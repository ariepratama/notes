# RAINIER: Reinforced Knowledge Introspector for Commonsense Question Answering 
Paper: https://aclanthology.org/2022.emnlp-main.611.pdf

Repo:  http://github.com/liujch1998/rainier

## New terms
* **Nucleus sampling**: Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2020. The curious case of neural text degeneration.
* **Imitation learning**. Generation of meaningful natural language statements that resemble knowledge. This will produce "silver dataset" of question-knowledge pairs.

## Premise
* Relevant knowledge provided as additional context -> enhance performance 
* Desired knowledge are sequences of discrete, non-differentiable word tokens ->  thus they can use reinforcement learning.

## Problem
* How to generate knowledge, given questions, to increase the performance / relevance of the QA model.

## Results
* Knowledge generated by other models, that is smaller than the GPT-3, can exceed the quality of commonsense knowledge drawn from GPT3

## Future works
* will it work on non commonsense applications?
* still leave large gap between model performance and human performance.
* limited length of knowledge 


